{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to https://github.com/zhixuhao/unet for the Unet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GoasmX8YXl_Q",
    "outputId": "1b7e4443-dcdd-4368-c9d4-536087cc1430"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "uNAShryrCbTo",
    "outputId": "7522c64f-a81d-4f67-e337-fe12c6bfec6f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install rasterio #used in Google Colab to install the library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%tensorflow_version 1.x magic\n",
    "import numpy as np\n",
    "import os\n",
    "import rasterio\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import time\n",
    "import skimage\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "'''Lines used in Google Colab to load files'''\n",
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (normalize, create_dataset, image_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "I1k8D5DXnGcZ"
   },
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "  return (array - array.min()) / (array.max() - array.min())\n",
    "\n",
    "def create_dataset(im, dim_size,stride):\n",
    "    \n",
    "  no_bands = len(im.indexes)\n",
    "  data = im.read()\n",
    "  bands = np.zeros([no_bands,im.shape[0],im.shape[1]])\n",
    "  for k in range(no_bands):\n",
    "    temp = data[k,:,:]\n",
    "    bands[k,:,:] = normalize(temp)\n",
    "      \n",
    "  global rows\n",
    "  global columns\n",
    "  rows = int((im.shape[0]-dim_size)/stride) + 1\n",
    "  columns = int((im.shape[1]-dim_size)/stride) + 1\n",
    "\n",
    "  dataset= np.zeros((rows*columns,dim_size,dim_size,no_bands))\n",
    "  # dataset = np.float16(dataset)\n",
    "  image_num = 0 \n",
    "  y_min = 0\n",
    "  y_max = dim_size\n",
    "  global orig_width\n",
    "  global orig_height\n",
    "  orig_height = im.shape[0]\n",
    "  orig_width = im.shape[1]\n",
    "  while (y_max)<orig_height:\n",
    "    x_min = 0\n",
    "    x_max = dim_size\n",
    "    while (x_max)<orig_width:\n",
    "      for k in range(no_bands):\n",
    "        temp = bands[k,y_min:y_max,x_min:x_max]\n",
    "        dataset[image_num,:,:,k] = temp\n",
    "      # plt.figure()\n",
    "      # plt.imshow(dataset[image_num,:,:,k],cmap='gray')\n",
    "      # plt.draw()\n",
    "      image_num = image_num + 1\n",
    "      x_min = x_min + stride\n",
    "      x_max = x_max + stride\n",
    "        \n",
    "    y_min = y_min + stride\n",
    "    y_max = y_max + stride\n",
    "  # dataset = np.float16(dataset)\n",
    "  return dataset,no_bands\n",
    "\n",
    "def image_tiles(path, image_size, stride,mask_path):\n",
    "  # Creating tiles for images\n",
    "  flag = True\n",
    "  # print(\"Processed \" + f)\n",
    "  im = rasterio.open(path)\n",
    "  mask = rasterio.open(mask_path)\n",
    "  [tempy, no_labels] = create_dataset(mask, image_size, stride)\n",
    "  [tempx, no_bands] = create_dataset(im, image_size, stride)\n",
    "  # tempy = np.float16(tempy)\n",
    "  # tempx = np.float16(tempx)\n",
    "  if flag:\n",
    "    flag = False\n",
    "    x = tempx\n",
    "    y = tempy\n",
    "  else:\n",
    "    x = np.concatenate([x, tempx],0)\n",
    "    y = np.concatenate([y, tempy],0)\n",
    "    # x = np.float16(x)\n",
    "    # y = np.float16(y)\n",
    "\n",
    "            \n",
    "  plt.figure(figsize=(15,15))\n",
    "  plt.imshow(im.read()[0,:,:],cmap='gray')\n",
    "  # plt.figure(figsize=(15,15))\n",
    "  # plt.imshow(mask.read()[0,:,:],cmap='gray')\n",
    "  print('Number of images generated: {} \\nNumber of labels generated: {}'.format(x.shape[0],y.shape[0]))\n",
    "  del tempx\n",
    "  del tempy\n",
    "  del im\n",
    "  del mask\n",
    "  return x, y, no_bands, no_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "ILBiOVu2CbT8",
    "outputId": "3f749e59-0fa9-4b7f-a318-f41c65841d3c"
   },
   "outputs": [],
   "source": [
    "image_size = 64 # New image size\n",
    "stride = 32 # Stride\n",
    "\n",
    "file_name = \"dem_rgbn_clipped_lidar.tif\"\n",
    "# file_name = \"elev_rgbn_clipped_lidar.tif\"\n",
    "# file_name = \"rgbn_clipped_lidar.tif\"\n",
    "# file_name = \"rgb_clipped_lidar.tif\"\n",
    "area_size = \"big\"\n",
    "\n",
    "train_image_path = \"./gdrive/My Drive/Jupyter Dataset/Lidar_Class/\"+area_size+\"/training_\" + file_name\n",
    "test_image_path = \"./gdrive/My Drive/Jupyter Dataset/Lidar_Class/\"+area_size+\"/validation_\" + file_name\n",
    "\n",
    "[x_train, y_train, no_bands, no_labels] = image_tiles(train_image_path,image_size,stride,\"./gdrive/My Drive/Jupyter Dataset/Lidar_Class/\"+area_size+\"/training_envi_final_mask.tif\")\n",
    "[x_valid, y_valid, no_bands, no_labels] = image_tiles(test_image_path,image_size,stride,\"./gdrive/My Drive/Jupyter Dataset/Lidar_Class/\"+area_size+\"/validation_envi_final_mask.tif\")\n",
    "no_classes = no_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "r6RU2ZCJd9VX"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, no_classes, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(no_classes, (1, 1), activation='softmax') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation and Parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2v9InGDmCbUM"
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR) # Supressing Warnings\n",
    "input_img = Input((image_size, image_size, no_bands), name='img')\n",
    "model = get_unet(input_img, no_labels, n_filters=16, dropout=0.25, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g-ZWKStYCbUZ",
    "outputId": "01159774-7944-465c-d89d-e9753bae579c"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "history = model.fit(x_train, y_train, epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "B69ejpQS5qIP",
    "outputId": "65774887-8c9a-48ba-c250-31f0345afe56"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.tight_layout()\n",
    "ax = plt.figure(figsize = (16,6)).gca()\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim((0,1))\n",
    "plt.xlim((0,epochs))\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=epochs/5, integer=True))\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "plt.savefig('plot_1.png', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "MCu4UEUJaTwa",
    "outputId": "ae93c275-7b8c-4ae5-8203-d5671f85f3ef"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.tight_layout()\n",
    "ax = plt.figure(figsize = (16,6)).gca()\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim((0,1))\n",
    "plt.xlim((0,epochs))\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=epochs/5, integer=True))\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "plt.savefig('plot_2.png', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "OGGcH-aV_mAN"
   },
   "outputs": [],
   "source": [
    "def image_reconstruction(data, dim_size, stride, rows=rows, columns=columns):\n",
    "  no_original_images = int(data.shape[0]/(rows*columns))\n",
    "  var1 = data.shape[0]\n",
    "  original_images = {}\n",
    "  im_num = 0\n",
    "  if dim_size == stride:\n",
    "    for im in range(no_original_images):\n",
    "      og_image= []\n",
    "      flag2 = True\n",
    "      for c in range(rows):\n",
    "        row = []\n",
    "        flag = True\n",
    "        for p in range(columns):\n",
    "          # plt.figure()\n",
    "          # plt.imshow(data[im_num,:,:,0],cmap='gray')\n",
    "          if flag:\n",
    "            temp = data[im_num,:,:,:]\n",
    "            row = temp\n",
    "            flag = False\n",
    "          else:\n",
    "            temp = data[im_num,:,:,:]\n",
    "            row = np.concatenate((row,temp), axis=1)\n",
    "          im_num = im_num + 1\n",
    "        if flag2:\n",
    "          og_image = row\n",
    "          flag2 = False\n",
    "        else:\n",
    "          og_image = np.concatenate((og_image, row), axis=0)\n",
    "      original_images[im] = og_image\n",
    "\n",
    "  else:\n",
    "    for im in range(no_original_images):\n",
    "      og_image= []\n",
    "      y_max=dim_size\n",
    "      while y_max<orig_height and im_num<var1:\n",
    "          row = []\n",
    "          x_max=dim_size\n",
    "          flag=True\n",
    "          while x_max<orig_width and im_num<var1:\n",
    "            if flag==True and y_max==dim_size and x_max==dim_size:\n",
    "              temp = data[im_num,:,:,:]\n",
    "              row = temp\n",
    "              flag=False\n",
    "            if flag==True and y_max>dim_size:\n",
    "              temp = data[im_num,stride:,:,:]\n",
    "              row = temp\n",
    "              flag=False\n",
    "            if flag==False and y_max==dim_size and x_max>dim_size:\n",
    "              temp = data[im_num,:,stride:,:]\n",
    "              row = np.concatenate((row,temp), axis=1)\n",
    "            if flag==False and y_max>dim_size and x_max>dim_size:\n",
    "              temp = data[im_num,stride:,stride:,:]\n",
    "              row = np.concatenate((row,temp), axis=1)\n",
    "            x_max = x_max + stride\n",
    "            im_num = im_num + 1\n",
    "          if y_max==dim_size:\n",
    "            og_image = row\n",
    "          else:\n",
    "            og_image = np.concatenate((og_image, row), axis=0)\n",
    "          y_max = y_max + stride\n",
    "          original_images[im] = og_image\n",
    "\n",
    "  return original_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzEnpCgQCbUm"
   },
   "outputs": [],
   "source": [
    "result = model.predict(x_valid)\n",
    "for i in range(no_labels):\n",
    "  result[:,:,:,i] = result[:,:,:,i] > 0.5\n",
    "result_final = image_reconstruction(result, image_size, stride)\n",
    "y_valid_final = image_reconstruction(y_valid, image_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predictions for every class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vQDmejfDAUC6",
    "outputId": "d5a4c052-7f1a-4bbb-b843-1a1fe3e57963"
   },
   "outputs": [],
   "source": [
    "\n",
    "im_result = result_final[0] #prediction for the first image in the test dataset\n",
    "im_y_valid = y_valid_final[0]\n",
    "\n",
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(2,no_labels,figsize=(25,20))\n",
    "\n",
    "# class_names = ['Buildings with tiling','Road',\n",
    "#               'Sparse Vegetation','Forests',\n",
    "#               'Buildings w/o tiling',\n",
    "#               'Bare Land','Sea','No Data' ] # first ground truth\n",
    "\n",
    "class_names = ['Buildings',\n",
    "               'No Data',\n",
    "              'Sparse Vegetation','Bare Land','Rocks',\n",
    "               'Sea','Forests',\n",
    "              'Roads'\n",
    "               ]# second ground truth\n",
    "\n",
    "for i in range(no_labels):\n",
    "  ax[0,i].set_title('Pred. - '+ class_names[i])\n",
    "  ax[0,i].imshow(im_result[:,:,i], cmap='gray')\n",
    "  ax[0,i].axis('off')\n",
    "  ax[1,i].set_title('Orig. - '+ class_names[i])\n",
    "  ax[1,i].imshow(im_y_valid[:,:,i], cmap='gray')\n",
    "  ax[1,i].axis('off')\n",
    "# plt.tight_layout()\n",
    "fig.savefig('plot_3', bbox_inches='tight',dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting validation predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3-KDoT1uRObt",
    "outputId": "b37436f4-e390-4cad-e8e1-af4f2227933f"
   },
   "outputs": [],
   "source": [
    "#@title Validation Plot\n",
    "im_result_colors = np.zeros((im_result.shape[0],im_result.shape[1]))\n",
    "im_y_valid_colors = np.zeros((im_y_valid.shape[0],im_y_valid.shape[1]))\n",
    "for k in range(im_result.shape[2]):\n",
    "  im_result_colors = im_result_colors + im_result[:,:,k]*k\n",
    "  im_y_valid_colors = im_y_valid_colors + im_y_valid[:,:,k]*k\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "'''First ground truth'''\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",\n",
    "# [\n",
    "# matplotlib.colors.to_rgb([1,0,0]), # 'Disc. Urban Fabric'\n",
    "#  matplotlib.colors.to_rgb([0.8,0.8,0.8]), # 'Roads'\n",
    "#  matplotlib.colors.to_rgb([0.8,1,0.8]), # 'Sparsely Veg. Areas'\n",
    "#  matplotlib.colors.to_rgb([0,0.650980392,0]), # 'Coniferous Forest'\n",
    "#  matplotlib.colors.to_rgb([1,1,1]), # 'Building without roof' \n",
    "# \"sandybrown\", # Land/soil/ground\n",
    "#  \"lightblue\", # 'Sea'\n",
    "#  matplotlib.colors.to_rgb([0,0,0]) # 'No Data'\n",
    "# ])\n",
    "\n",
    "'''Second ground truth'''\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",\n",
    "[\n",
    "matplotlib.colors.to_rgb([1,0,0]), # 'Disc. Urban Fabric'\n",
    "matplotlib.colors.to_rgb([0,0,0]), # 'No Data'\n",
    "matplotlib.colors.to_rgb([0.8,1,0.8]), # 'Sparsely Veg. Areas'\n",
    "\"sandybrown\", # Land/soil/ground\n",
    "matplotlib.colors.to_rgb([0.8,0.8,0.8]), # 'Rocks'\n",
    "\"lightblue\", # 'Sea'\n",
    "matplotlib.colors.to_rgb([0,0.650980392,0]), # 'Coniferous Forest'\n",
    "matplotlib.colors.to_rgb([1,1,1]), # 'Roads'\n",
    "])\n",
    "\n",
    "plt.imshow(im_result_colors, cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.savefig('plot_4', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "F7kweier-woy"
   },
   "outputs": [],
   "source": [
    "def calc_conf_mat(px_min,px_max,py_min,py_max,im_result=im_result,im_y_valid=im_y_valid,class_names=class_names):\n",
    "  conf_mat = np.zeros((im_result.shape[2],im_y_valid.shape[2]),dtype=int)\n",
    "  result_classes = np.argmax(im_result,axis=2)\n",
    "  y_valid_classes = np.argmax(im_y_valid,axis=2)\n",
    "  test_counter = 0\n",
    "  for y in range(px_min,px_max):\n",
    "    for x in range(py_min,py_max):\n",
    "      conf_mat[y_valid_classes[x,y], result_classes[x,y]] = conf_mat[y_valid_classes[x,y],result_classes[x,y]]+ 1\n",
    "      test_counter += 1\n",
    "  df = pd.DataFrame(conf_mat, columns=class_names, index=class_names)\n",
    "  temp = []\n",
    "  for i in df:\n",
    "    temp.append(df[i].sum())\n",
    "  temp2 = []\n",
    "  for i in range(conf_mat.shape[0]):\n",
    "    temp2.append(conf_mat[i].sum())\n",
    "  temp2.append(np.sum(temp2))\n",
    "  df.loc['Total'] = temp\n",
    "  df['Total'] = temp2\n",
    "  # print(\"Overall Accuracy: %.4f\"%(accuracy))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring polygons - Calculating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "LcDofWFu-z3y",
    "outputId": "eccba4f3-3ae4-4acf-ba06-fb22fd9a7a31"
   },
   "outputs": [],
   "source": [
    "px1_min, py1_min = (50,500)\n",
    "px1_max, py1_max = (px1_min +200, py1_min +200)\n",
    "p1 = [[px1_max,py1_max], [px1_min,py1_max], [px1_min,py1_min], [px1_max,py1_min],[px1_max,py1_max]]\n",
    "px2_min, py2_min = (200,2905)\n",
    "px2_max, py2_max = (px2_min +75, py2_min +150)\n",
    "p2 = [[px2_max,py2_max], [px2_min,py2_max], [px2_min,py2_min], [px2_max,py2_min],[px2_max,py2_max]]\n",
    "px3_min, py3_min = (200,1000)\n",
    "px3_max, py3_max = (px3_min +100, py3_min +100)\n",
    "p3 = [[px3_max,py3_max], [px3_min,py3_max], [px3_min,py3_min], [px3_max,py3_min],[px3_max,py3_max]]\n",
    "px4_min, py4_min = (660,400)\n",
    "px4_max, py4_max = (px4_min +100, py4_min +100)\n",
    "p4 = [[px4_max,py4_max], [px4_min,py4_max], [px4_min,py4_min], [px4_max,py4_min],[px4_max,py4_max]]\n",
    "\n",
    "df1\t  =\tcalc_conf_mat(\tpx1_min\t\t,\tpx1_max\t\t,\tpy1_min\t\t,\tpy1_max\t\t)\n",
    "df2\t  =\tcalc_conf_mat(\tpx2_min\t\t,\tpx2_max\t\t,\tpy2_min\t\t,\tpy2_max\t\t)\n",
    "df3\t  =\tcalc_conf_mat(\tpx3_min\t\t,\tpx3_max\t\t,\tpy3_min\t\t,\tpy3_max\t\t)\n",
    "df4\t  =\tcalc_conf_mat(\tpx4_min\t\t,\tpx4_max\t\t,\tpy4_min\t\t,\tpy4_max\t\t)\n",
    "\n",
    "\n",
    "df_final = df1 + \tdf2 + df3 + df4\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omission/Commission Errors - Total Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "gU3fGOap-8dR",
    "outputId": "5fde7fff-1e6f-4881-d475-34ee98fa43e1"
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "diagonal = 0\n",
    "for i in df_final:\n",
    "  if i == 'Total':\n",
    "    break\n",
    "  else:\n",
    "    diagonal = diagonal + df_final[i][i]\n",
    "  if df_final[i][-1] == 0:\n",
    "    commission_error = 0\n",
    "  else:\n",
    "    commission_error = (df_final[i][-1] - df_final[i][counter]) / df_final[i][-1]\n",
    "  if df_final.loc[i][-1] == 0:\n",
    "    omission_error = 0\n",
    "  else:\n",
    "    omission_error = (df_final.loc[i][-1] - df_final.loc[i][counter]) / df_final.loc[i][-1]\n",
    "  counter += 1\n",
    "  \n",
    "  print('%s\\nOmission Error: %.1f %% , Commission Error: %.1f %% \\n'%(i, omission_error*100,commission_error*100))\n",
    "accuracy = diagonal/df_final['Total']['Total']\n",
    "print(\"Overall Accuracy: %.1f %%\"%(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "a-BJMpy1a7fR",
    "outputId": "ccf5527d-0021-44ff-a533-0964e3697e9f"
   },
   "outputs": [],
   "source": [
    "temp = y_valid_final[0][:,:,-1]\n",
    "indices = temp<1\n",
    "for i in y_valid_final:\n",
    "  tim1 = y_valid_final[i].astype(float)\n",
    "  tim2 = result_final[i].astype(float)\n",
    "  total = skimage.metrics.structural_similarity(tim1, tim2)\n",
    "  tim3 = y_valid_final[i][indices,:].astype(float)\n",
    "  tim4 = result_final[i][indices,:].astype(float)\n",
    "  inner = skimage.metrics.structural_similarity(tim3, tim4)\n",
    "  print(\"Image\",i+1)\n",
    "  print(\"Total similarity: %.4f\\nInner similarity: %.4f\\n\"%(total,inner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating weight significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "GKHf6P9Bll8p",
    "outputId": "ba4bb1ba-5234-43df-b380-cbf0e89de967"
   },
   "outputs": [],
   "source": [
    "#@title Weight significance\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "print(filters.shape)\n",
    "for i in range(filters.shape[2]):\n",
    "  print(np.sum(abs(filters[:,:,i,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot image with Conf. Matrix polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "32-qFlj7_GeI",
    "outputId": "14c84d3f-efa8-4d29-b878-02c657234e27"
   },
   "outputs": [],
   "source": [
    "#@title Plot\n",
    "im_result_colors = np.zeros((im_result.shape[0],im_result.shape[1]))\n",
    "im_y_valid_colors = np.zeros((im_y_valid.shape[0],im_y_valid.shape[1]))\n",
    "for k in range(im_result.shape[2]):\n",
    "  im_result_colors = im_result_colors + im_result[:,:,k]*k\n",
    "  im_y_valid_colors = im_y_valid_colors + im_y_valid[:,:,k]*k\n",
    "\n",
    "fig = plt.figure(1, figsize=(20, 20))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(im_result_colors, cmap=cmap)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "xp1\t  ,\typ1\t  =\tzip(\t*p1\t  )\n",
    "xp2\t  ,\typ2\t  =\tzip(\t*p2\t  )\n",
    "xp3\t  ,\typ3\t  =\tzip(\t*p3\t  )\n",
    "xp4\t  ,\typ4\t  =\tzip(\t*p4\t  )\n",
    "\n",
    "ax.plot(\txp1\t,\typ1\t,\t'r-'\t)\n",
    "ax.plot(\txp2\t,\typ2\t,\t'r-'\t)\n",
    "ax.plot(\txp3\t,\typ3\t,\t'r-'\t)\n",
    "ax.plot(\txp4\t,\typ4\t,\t'r-'\t)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "(old)Lidar Data Classification1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
